# -*- coding: utf-8 -*-
# -*- mode: org -*-
#+startup: beamer overview indent
#+LANGUAGE: pt-br
#+TAGS: noexport(n)
#+EXPORT_EXCLUDE_TAGS: noexport
#+EXPORT_SELECT_TAGS: export

#+Title: Comp. Syst. Perf. Analysis
#+SubTitle: Measurement
#+Author: Prof. Lucas Mello Schnorr
#+Date: \copyleft

#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [xcolor=dvipsnames,10pt]
#+OPTIONS: H:1 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+LATEX_HEADER: \input{org-babel.tex}

* Introduction to Monitoring (Measurement)

- Monitors are tools to observe system activities
  - Collect statistics, analyze data, display results
  - Some can identify problems and suggest fixes

#+latex: \vfill\pause

Who uses monitors and why?
- *System programmer*: optimize frequently used software segments
- *System manager*: measure res. utilization, detect bottlenecks, tune system
- *System analyst*: characterize workloads, plan capacity, create test workloads
- *Modeling tasks*: find parameters, validate, and develop model inputs

#+latex: \vfill\pause


** Key Point                                                       :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:

Monitoring is the **first and essential step** in performance
measurement

* Monitor-Related Terms

- Event: change in system state  
  - e.g., context switch, disk seek start, packet arrival  

#+latex: \pause\vfill

- Trace: log of events  
  - includes time, type, and relevant parameters  

#+latex: \pause\vfill

- Overhead: resource consumption by monitoring  
  - e.g., CPU/storage use for data collection  
  - goal: keep it minimal (*sometimes called artifact*)  

#+latex: \pause\vfill

- Domain: set of observable activities  
  - e.g., CPU time, I/O counts, user session duration  

#+latex: \pause\vfill

- Input Rate: maximum frequency of observable events  
  - *burst mode*: short high rate  
  - *sustained*: long-term rate  

#+latex: \pause\vfill

- Resolution: granularity of observation  
  - e.g., time units (16 ms), histogram bucket size  

#+latex: \pause\vfill

- Input Width: bits recorded per event  
  - with input rate → determines storage needs

* Monitor Classification

- By implementation level  
  - Software, Hardware, Firmware, or Hybrid (most common)  

#+latex: \pause\vfill

- By trigger mechanism  
  - Event-driven: activated on specific events  
    - low overhead if events rare, high if frequent
    - Methods: 1/ counting /vs/ 2/ timing /vs/ 3/ tracing (or logging)

  - Timer-driven (sampling): periodic activation  
    - good for frequent events, resolution depends on sampling freq.
    - Methods: sampling

#+latex: \pause\vfill

- By result display  
  - On-line: shows state continuously or at intervals  
  - Batch: collects data for later analysis  

#+latex: \pause\vfill

** Combined classification                                         :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
  - e.g., *hybrid–sampling–batch monitor*  

* Software Monitors

- Monitor operating systems, networks, databases  
- Each activation executes many instructions → suitable for **low input rates**  

#+latex: \pause\vfill

- Example: 100 instr/event on 1-MIPS machine → 0.1 ms/event  
  - To keep overhead ≤ 1%, activate every 10 ms or less  
  - Input rate < 100 events/s  

#+latex: \pause\vfill

- Special case: instruction-tracing monitors  
  - Can tolerate high overhead if execution *path* not affected
  - Attached to simulators (the world stops while you trace)

#+latex: \pause\vfill

** Comparison with hardware monitors                               :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
  - Lower input rate, lower resolution, higher overhead  
  - Higher input width & recording capacity  
  - Easier to develop and modify  

* Software Monitor Design: Core Issues

- Activation mechanisms  
  - Trap instruction → similar to subroutine call  
  - Trace mode → interrupts after each instruction, high overhead  
  - Timer interrupt → sampling, efficient for frequent events  

#+latex: \pause\vfill

- Buffer management  
  - Size trade-off: too small → frequent writes, too large → memory impact  
  - Multiple buffers (ring organization) enable continuous operation  
  - Buffer overflow → choice between losing old vs. new data  
  - Counter overflows should also be recorded

* Software Monitor Design: Practical Considerations

- Data compression/analysis  
  - Reduces storage needs, but increases overhead  

#+latex: \pause\vfill

- On/Off control  
  - Conditional activation (IF … THEN …)  
  - Important for debugging & reducing overhead  

#+latex: \pause\vfill

- Implementation details \to _depends a lot on the monitored comp. object_
  - Language: low-level (Assembly, C)
  - Priority: low to avoid interference, high if timely logging is critical  
  - Abnormal events: often higher monitoring priority than normal events

* Hardware Monitors

- External probes and counters @@latex:\linebreak@@
  → No system resources consumed → very low overhead @@latex:\linebreak@@
  → Higher input rate & reduced risk of bugs  
- Built-in in the HW design
  - Gigantic choice, all depending on HW specifics
  
#+latex: \pause\vfill

- Key elements: probes, _counters_, logic, comparators, timers, storage

#+latex: \pause\vfill

** Example: **PAPI hardware counters**  
  - Homogeneous set of normalized counters
    - Mapped to different HW counters depending on processor
  - Designed to evaluate processor performance  
    - Measure events: cache misses, branch mispredictions, FLOPs, cycles  
  - Useful for monitoring computational programs   @@latex:    \pause\vfill@@

Attention
  - May have a enourmous variability across runs and architectures  
  - Guide performance tuning and bottleneck identification  


* Hardware vs Software Monitors

A debatable comparison table

#+ATTR_LATEX: :center no :booktabs true
|--------------------+-------------------------+------------------------------|
| *Criteria*           | *Hardware Monitor*        | *Software Monitor*             |
|--------------------+-------------------------+------------------------------|
| Input rate         | 10^5 per second possible | Limited monitoring overhead  |
|--------------------+-------------------------+------------------------------|
| Time resolution    | 10 nanoseconds possible | Generally 10–16 milliseconds |
|--------------------+-------------------------+------------------------------|
| Recording capacity | Not an issue in general | Limited by overhead desired  |
|--------------------+-------------------------+------------------------------|
| Input width        | Simultaneous events     | Cannot                       |
|                    |                         | (unless multiple processors) |
|--------------------+-------------------------+------------------------------|
| Overhead           | None                    | Overhead depends a lot       |
|                    |                         | (5% adequate, 100% possible) |
|--------------------+-------------------------+------------------------------|
| Cost               | High                    | Medium                       |
|--------------------+-------------------------+------------------------------|


* Distributed-System Monitors

- Nowadays, most computing environments are distributed  
  + Many hardware and software components  
  + Working separately and concurrently  

- Monitoring becomes more complex than in centralized systems  
  + The monitor itself must also be distributed  
  + Several components, running concurrently  

- Design issues and terminology apply to:  
  + Networks (case study)  
  + Multicomputer systems  
  + Distributed databases  
  + Even non-distributed systems in some aspects


** Key point: monitoring a distributed environment requires        :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
  coordination, concurrency, distributed observation, and clock synchronization


* Layered View of a Distributed-System Monitor

- Observation :: Raw data gathering on each component (local observers)  
- Collection :: Collects data from multiple observers  
- Analysis :: Statistical routines, event summarization  
- Presentation :: Reports, displays, alarms for users  
- Interpretation :: Human/expert system applies rules & trend analysis  
- Console :: Interface for control + observation  
- Management :: Decides & changes parameters/configurations

#+latex: \vfill\pause

#+attr_latex: :width .4\linewidth
[[./img/distr-syst-layered-obs.png]]

* Observation \to Raw Data Gathering

Focused on gathering raw data from system components

Three main observation mechanisms
- Implicit Spying  
  - Promiscuous observation of system bus or network  
  - Minimal impact on performance  
  - Often combined with filters (Boolean, arithmetic, set membership)  
#+latex: \pause

- Explicit Instrumenting  
  - Adding trace points, probe points, hooks, or counters  
  - Causes some overhead  
  - Standardized data naming helps device-independent reporting  

#+latex: \pause

- Probing  
  - Sends "feeler" requests to sense current performance  
  - Example: looped-back network packets to measure queueing and load  
  - Useful for diagnostics and reliability analysis

** Key point                                                       :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
Usually, a combination of the three mechanisms is used to cover all observable activities

* Collection \to Data Gathering Layer

Collector: repository for data from multiple observers

Observers vs. Collectors
- Observation has higher overhead than collection
- Separating layers reduces monitoring impact

#+latex: \pause

Communication models:
- **Advertising:** observers broadcast data for all collectors
- **Soliciting:** collectors query each observer individually
  - Queries can be periodic or event-driven

#+latex: \pause

Hierarchical collectors
  - Large systems: subnetwork collectors aggregate data from local observers

#+latex: \pause    
 
Clock synchronization
- Timestamps must be comparable across observers
- Maximum skew affects aggregation intervals
- Causality of events _must be respected_
  - Independent collection \to Harder post-processing of events

#+latex: \pause

Collectors may store past data → buffer and sampling issues apply

* Analysis \to Processing Collected Data

Analyzer: performs more sophisticated data processing

Criteria to decide where a function belongs:
1. Frequency: high-frequency operations → observer; infrequent → analyzer
2. Data required: functions needing global data → analyzer
3. Complexity: complex computations → analyzer
4. Number of instances: many observers vs. fewer analyzers → push complexity to analyzer

#+latex: \vfill\pause

Examples:
- Time stamping, counting → observer
- Means, variances, identifying links with highest errors → analyzer
- Goal: simplify as much as possible the observers
  - Move complexity to infrequent analysis

* Examples
* References

#+latex: {\small
- Chapter 7. Jain, Raj. The art of computer systems performance
  analysis: techniques for experimental design, measurement,
  simulation, and modeling. New York: John Wiley,
  c1991. ISBN 0471503363.
- March, 20th, 2014: Análise de Desempenho de Programas
  Paralelos. Lucas Mello Schnorr. Short course (3 hours) prepared for
  the ERAD/RS 2014. Alegrete, RS, Brazil. Both slides and text in
  Portuguese.
#+latex: }
